INTRODUCTION

  This is zfp 0.3.1, an open source C++ library for compressed floating-point
  arrays that support high throughput read and write random access.  zfp was
  written by Peter Lindstrom at Lawrence Livermore National Laboratory, and
  is based on the algorithm described in the following paper:

    Peter Lindstrom
    "Fixed-Rate Compressed Floating-Point Arrays"
    IEEE Transactions on Visualization and Computer Graphics,
      20(12):2674-2683, December 2014
    doi:10.1109/TVCG.2014.2346458

  zfp was designed to achieve high compression ratios and therefore uses
  lossy but optionally error-bounded compression.  Although bit-for-bit
  lossless compression is not always possible, zfp is usually accurate to
  within machine epsilon in near-lossless mode.

  zfp works best for 2D and 3D arrays that exhibit spatial coherence.
  Although zfp also provides a 1D array class that can be used for 1D
  signals or even unstructured floating-point streams, the compression
  scheme has not been well optimized for this use case, and rate and quality
  may not be competitive with floating-point compressors designed for 1D
  streams.

  zfp is freely available as open source under a BSD license, as outlined in
  the file 'LICENSE'.  For information on the API and general usage, please
  see the file 'API' in this directory.


INSTALLATION

  The main compression codec and array classes are implemented entirely in
  header files, and therefore can be included as is without pre-compilation.
  C wrappers also exist for compressing entire arrays, which are made
  available through a small library called libzfp.  To compile libzfp and
  all example programs (see below for more details) on Linux or OS X, type

    make

  from this directory.  Then, to test the compressor using testzfp, type

    make test

  If the compilation or regression tests fail, it is possible that some of
  the macros in the file 'Config' have to be adjusted.  Also, the tests may
  fail due to minute differences in the computed floating-point fields
  being compressed (as indicated by checksum errors).  It is surprisingly
  difficult to portably generate a floating-point array that agrees
  bit-for-bit across platforms.  If most tests succeed and the failures
  result in byte sizes and error values reasonably close to the expected
  values, then it is likely that the compressor is working correctly.

  NOTE: zfp requires 64-bit compiler and operating system support.

  zfp has successfully been built and tested using these compilers:

    gcc versions 4.4.7, 4.7.2, 4.8.2, 4.9.1
    icc versions 12.0.5, 12.1.5, 13.0.1, 14.0.3
    xlc version 12.1
    clang versions 3.2 3.4.2
    mingw32-gcc version 4.8.1


ALGORITHM OVERVIEW

  The zfp lossy compression scheme is based on the idea of breaking a
  d-dimensional array into independent blocks of 4^d values, e.g. 4x4x4
  values in three dimensions.  Each block is compressed/decompressed
  entirely independently from all other blocks.  In this sense, zfp is
  similar to current hardware texture compression schemes for image
  coding implemented on graphics cards and mobile devices.

  The zfp compression scheme is based on three components, outlined below.

  (1) The d-dimensional array is partitioned into blocks of dimensions 4^d.
  The independent floating-point values in a block are converted to what is
  known as a block-floating-point representation, which uses a single, common
  floating-point exponent for all 4^d values.  The effect of this conversion
  is to turn each floating-point value into a 32- or 64-bit signed integer.

  (2) The integers are decorrelated using a custom, high-speed, orthogonal
  transform similar to the discrete cosine transform used in JPEG image
  coding.  The transform exploits separability and is implemented efficiently
  in-place using the lifting scheme.  If the data is "smooth," then this
  transform will turn most integers into small signed values clustered
  around zero.

  (3) The transform coefficients are compressed using embedded coding by
  exploiting the property that most coefficients have many leading zeros.
  This coder emits one bit at a time, with each successive bit potentially
  improving the quality of the reconstructed signal.  The early bits are
  most important and have the greatest impact on signal quality, with the
  last few bits providing very small changes.  The resulting compressed
  bit stream can be truncated at any point and still allow for a valid
  reconstruction.  This property is the basis for the fixed-rate
  functionality and random access to fixed-size blocks supported by zfp.

  Various parameters are exposed for controlling the quality and compressed
  size of a block, and can be specified by the user at a very fine
  granularity.  These parameters are discussed below.


CODE EXAMPLES

  The 'examples' directory includes three programs that make use of the
  compressor.  'testzfp' provides regression testing that exercises most
  of the functionality of libzfp and the array classes.  The tests assume
  the default compiler settings, i.e. with none of the macros in Config
  defined.

  The 'diffusion' example is a simple forward Euler solver for the heat
  equation on a 2D regular grid, and is intended to show how to declare
  and work with zfp's compressed arrays, as well as give an idea of how
  changing the compression rate affects the error in the solution.  It is
  possible to compile this code with conventional uncompressed arrays for
  comparison (see the Config macro WITHOUT_COMPRESSION).  The usage is:

    diffusion [rate] [nx] [ny] [nt]

  where 'rate' specifies the exact number of compressed bits to store per
  double-precision floating-point value (default = 64); 'nx' and 'ny'
  specify the grid size (default = 100x100); and 'nt' specifies the number
  of time steps to run (the default is to run until time t = 1).

  Running diffusion with the following arguments

    diffusion 10.5
    diffusion 32
    diffusion 64

  should result in this output

    rate=10.5 sum=0.990821 error=1.531267e-06
    rate=32 sum=0.998326 error=1.967958e-07
    rate=64 sum=0.998326 error=1.967957e-07

  The 'zfp' program is intended for evaluating the rate-distortion
  (compression rate and quality) provided by the compressor.  It either
  generates a test data set or takes a raw array of floats or doubles as
  input.  It optionally outputs the reconstructed array obtained after
  lossy compression followed by decompression.  Various statistics on
  compression rate and error are also displayed.

  The zfp usage is:

    zfp [options] <nx> [ny nz infile outfile]

  The floating-point precision (single or double) must be specified using
  either -f (float) or -d (double).  Additional options are available
  for specifying compression parameters, and are discussed below.

  zfp takes three arguments for array dimensions.  For 3D arrays of
  dimensions nx * ny * nz, x varies faster than y, which in turn varies
  faster than z.  That is, the input file should correspond to a flattened
  C array declared as a[nz][ny][nx].  For 2D arrays, specify nz = 0 (or
  leave this argument out); for 1D arrays, set ny = nz = 0.  Note that if
  nz is set to one for a 2D array, then the data will be treated as 3D and
  padded, which may negatively impact the compression rate or quality.
  Similarly, if ny = 1, nz = 0, then the data will be treated as 2D rather
  than 1D.

  In addition to the array dimensions, zfp accepts several options for
  specifying how the data is to be compressed.  The most general of these,
  the -c option, takes four constraint parameters that together can be
  used to achieve various effects.  These constraints are:

    minbits: the minimum number of bits used to represent a block
    maxbits: the maximum number of bits used to represent a block
    maxprec: the maximum number of bit planes encoded
    minexp:  the smallest bit plane number encoded

  Options -r, -p, and -a provide a simpler interface to setting all of
  the above parameters (see below).  Bit plane e refers to those bits whose
  place value is 2^e.  For instance, in single precision, bit planes -149
  through 127 are supported (when also counting denormalized numbers); for
  double precision, bit planes -1074 through 1023 are supported.

  Care must be taken to allow all constraints to be met, as encoding
  terminates as soon as a single constraint is violated (except minbits,
  which is satisfied at the end of encoding by padding zeros).  The effects
  of the above four parameters are best explained in terms of the three main
  compression modes supported by zfp (see Algorithm Overview above for
  additional details):

  Fixed rate (option -r):
    In fixed-rate mode, each compressed block of 4^d values in d dimensions
    is stored using a fixed number of bits specified by the user.  This can
    be achieved using option -c by setting minbits = maxbits, maxprec = 0,
    and minexp = INT_MIN.  The fixed-rate mode is needed to support random
    access to blocks, where the amortized number of bits used per value is
    given by rate = maxbits / 4^d.  Note that each block stores a common
    exponent, and maxbits must be at least 8 for single precision and 11
    for double precision.

  Fixed precision (option -p): 
    In fixed-precision mode, the number of bits used to encode a block may
    vary, but the number of bit planes (i.e. the precision) encoded for the
    transform coefficients is fixed.  This mode is achieved by specifying
    the precision in maxprec and fully relaxing the size constraints, i.e.
    minbits = 0, maxbits = UINT_MAX, and minexp = INT_MIN.  Fixed-precision
    mode is preferable when relative rather than absolute errors matter.

  Fixed accuracy (option -a):
    In fixed-accuracy mode, all transform coefficient bit planes up to a
    minimum bit plane number are encoded.  (The actual minimum bit plane
    is not necessarily minexp, but depends on the dimensionality of the
    data.  The reason for this is that the inverse transform incurs range
    expansion, and the amount of expansion depends on the number of
    dimensions.)  Thus, minexp should be interpreted as the base-2 logarithm
    of an absolute error tolerance.  In other words, given an uncompressed
    value f and a reconstructed value g, the absolute difference |f - g|
    is guaranteed to be at most 2^minexp.  (Note that it is not possible to
    guarantee error tolerances smaller than machine epsilon relative to the
    largest value within a block.)  This error tolerance is not always tight
    (especially for 3D arrays), but can conservatively be set so that even
    for worst-case inputs the error tolerance is respected.  To achieve
    fixed accuracy to within 'tolerance', use the -a <tolerance> option,
    which sets minexp = floor(log2(tolerance)), minbits = 0,
    maxbits = UINT_MAX, and minprec = 0.  As in fixed-precision mode, the
    number of bits used per block is not fixed but is dictated by the data.
    Use -a 0 to achieve near-lossless compression.  Fixed-accuracy mode
    gives the highest quality (in terms of absolute error) for a given
    compression rate, and is preferable when random access is not needed.

  As mentioned above, other combinations of constraints can be used.
  For example, to ensure that the compressed stream is not larger than
  the uncompressed one, or that it fits within the amount of memory
  allocated, one may in conjunction with other constraints set
  maxbits = 4^d * CHAR_BIT * sizeof(Type), where Type is either float or
  double.  The minbits parameter is useful only in fixed-rate mode--when
  minbits = maxbits, zero-bits are padded to blocks that compress to fewer
  than maxbits bits.

  The following invocations of zfp

    zfp -f -r 16 100 100 100
    zfp -d -r 32 1000000
    zfp -d -p 32 1000 1000
    zfp -d -a 1e-9 1000000
    zfp -d -c 64 64 0 -1074 1000000

  should result in the following output

    in=4000000 out=2000000 ratio=2 rate=16
      rmse=7.486e-10 nrmse=3.748e-10 maxe=2.98e-08 psnr=182.50
    in=8000000 out=4000000 ratio=2 rate=32
      rmse=5.411e-13 nrmse=2.705e-13 maxe=2.21e-12 psnr=245.34
    in=8000000 out=1698243 ratio=4.71 rate=13.59
      rmse=1.241e-09 nrmse=6.205e-10 maxe=6.453e-09 psnr=178.12
    in=8000000 out=2933987 ratio=2.73 rate=23.47
      rmse=2.021e-10 nrmse=1.01e-10 maxe=5.79e-10 psnr=193.89
    in=8000000 out=2000000 ratio=4 rate=16
      rmse=2.234e-07 nrmse=1.117e-07 maxe=9.473e-07 psnr=133.02

  Finally, the testzfp program performs regression testing.  By default,
  small, pregenerated floating-point arrays are used in the test, since
  they tend to have the same binary representation across platforms,
  whereas it can be difficult to computationally generate bit-for-bit
  identical arrays.  To test larger arrays, modify the TESTZFP_* macros
  in Config.  When large arrays are used, the (de)compression throughput
  is also measured and reported in number of uncompressed bytes per
  second.


LIMITATIONS AND MISSING FEATURES

  zfp is released as a beta version with the intent of giving people access
  to the code and soliciting feedback on how to improve zfp for the first
  full release.  As such, the zfp API is experimental and has not been
  fixed, and it is entirely possible that future versions will employ a
  different API or even a different codec.

  Below is a list of known limitations and desirable features that may make
  it into future versions of zfp.

  - The current version of zfp allows for near lossless compression through
    suitable parameter choices, but no guarantees are made that bit-for-bit
    lossless compression is achieved.  We envision supporting lossless
    compression in a future version by compressing the difference between
    the original data and nearly losslessly compressed data.

  - Special values like infinity and NaN are not supported.  Denormalized
    floating-point numbers are, however, correctly handled.  There is an
    implicit assumption that floating point conforms to IEEE, though
    extensions to other floating-point formats should be possible with
    minor effort.

  - Currently no compressed format exists for storing compressed arrays
    externally, e.g. on disk.  Although it is possible to compress data
    to memory and write the compressed stream out, no meta data is
    embedded in the stream, and it is entirely up to the user to ensure
    that the data is read back in and interpreted according to the original
    array dimensions and floating-point type.

  - No iterators are provided for traversing an array, and currently one
    has to use integer indexing.  Performance could in cases be improved
    by limiting the traversal to sequential access.

  - It is not possible to access subarrays via pointers, e.g. via
    double* p = &a[offset]; p[i] = ...  A pointer proxy class similar to
    the reference class would be useful.

  - There currently is no way to make a complete copy of a compressed
    array, i.e. a = b; does not work for arrays a and b.

  - zfp can potentially provide higher precision than conventional float
    and double arrays, but the interface currently does not expose this.
    For example, such added precision could be useful in finite difference
    computations, where catastrophic cancellation can be an issue when
    insufficient precision is available.

  - Only single and double precision types are supported.  Generalizations
    to IEEE half and quad precision would be useful.  For instance,
    compressed 64-bit-per-value storage of 128-bit quad-precision numbers
    could greatly improve the accuracy of double-precision floating-point
    computations using the same amount of storage.

  - zfp arrays are not thread-safe.  We are considering options for
    supporting multi-threaded access, e.g. for OpenMP parallelization.

  - zfp does not run on the GPU.  We hope to port zfp to the GPU within
    the next few months.


QUESTIONS, COMMENTS, AND BUG REPORTS

  For bug reports, questions, and suggestions for improvements, please
  contact Peter Lindstrom at pl@llnl.gov.
